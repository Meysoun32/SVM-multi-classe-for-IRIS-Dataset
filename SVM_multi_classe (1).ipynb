{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **SVM multi-classe**"
      ],
      "metadata": {
        "id": "vauH0gOxZtNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Support Vector Machine (SVM) est un algorithme d'apprentissage automatique supervisé utilisé pour les tâches de classification et de régression. En ce qui concerne la classification multi-classes, où il y a plus de deux classes, SVM peut être étendu de différentes manières pour gérer ce scénario. Deux approches courantes sont \"One against One\" et \"One against All\" (également appelées \"One versus One\" et \"One versus All\").\n"
      ],
      "metadata": {
        "id": "zfdNmVolZnuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One against All (One versus Rest):**\n",
        "\n",
        "One-vs-rest (OvR, abréviation d'One-vs-All ou OvA) est une méthode heuristique pour utiliser des algorithmes de classification binaire dans le cadre de la classification multi-classes.\n",
        "\n",
        "Elle consiste à diviser l'ensemble de données multi-classes en plusieurs problèmes de classification binaire. Un classificateur binaire est ensuite entraîné pour chaque problème de classification binaire, et les prédictions sont effectuées en utilisant le modèle le plus confiant.\n",
        "\n",
        "Par exemple, considérons un problème de classification multi-classes avec des exemples pour chaque classe 'rouge', 'bleu' et 'vert'. Cela pourrait être divisé en trois ensembles de données de classification binaire comme suit :\n",
        "\n",
        "* Problème de Classification Binaire 1 : rouge vs [bleu, vert]\n",
        "\n",
        "* Problème de Classification Binaire 2 : bleu vs [rouge, vert]\n",
        "\n",
        "* Problème de Classification Binaire 3 : vert vs [rouge, bleu]\n",
        "\n",
        "\n",
        "**Un inconvénient** possible de cette approche est qu'elle nécessite la création d'un modèle pour chaque classe. Par exemple, trois classes nécessitent trois modèles. Cela peut poser problème pour des ensembles de données volumineux (par exemple, des millions de lignes), des modèles lents (par exemple, des réseaux neuronaux) ou un très grand nombre de classes (par exemple, des centaines de classes).\n",
        "Cette approche nécessite que chaque modèle prédise une probabilité d'appartenance à une classe ou un score semblable à une probabilité. L'argmax de ces scores (indice de classe avec le score le plus élevé) est ensuite utilisé pour prédire une classe.\n",
        "\n",
        "Cette approche est couramment utilisée pour les algorithmes qui prédisent naturellement une probabilité d'appartenance à une classe ou un score numérique, tels que :\n",
        "\n",
        "* Régression logistique\n",
        "* Perceptron\n",
        "En conséquence, l'implémentation de ces algorithmes dans la bibliothèque scikit-learn utilise par défaut la stratégie OvR lors de l'utilisation de ces algorithmes pour la classification multi-classes.\n",
        "\n",
        "Nous pouvons le démontrer avec un exemple sur un problème de classification à 3 classes en utilisant l'algorithme LogisticRegression. La stratégie de gestion de la classification multi-classes peut être définie via l'argument \"multi_class\" et peut être réglée sur \"ovr\" pour la stratégie one-vs-rest.\n",
        "\n",
        "**L'exemple complet** d'ajustement d'un modèle de régression logistique pour la classification multi-classes en utilisant la stratégie intégrée one-vs-rest est présenté ci-dessous.\n"
      ],
      "metadata": {
        "id": "92NqI36lZ6xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression for multi-class classification using built-in one-vs-rest\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "# define model\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make predictions\n",
        "yhat = model.predict(X)"
      ],
      "metadata": {
        "id": "lPSfZ_OecRPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scikit-learn library also provides a separate **OneVsRestClassifier** class that allows the one-vs-rest strategy to be used with any classifier."
      ],
      "metadata": {
        "id": "ezkUgJTyczdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# logistic regression for multi-class classification using a one-vs-rest\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "# define model\n",
        "model = LogisticRegression()\n",
        "# define the ovr strategy\n",
        "ovr = OneVsRestClassifier(model)\n",
        "# fit model\n",
        "ovr.fit(X, y)\n",
        "# make predictions\n",
        "yhat = ovr.predict(X)"
      ],
      "metadata": {
        "id": "hGuimM2Mc2Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One-vs-One**\n",
        "One-vs-One est une autre méthode heuristique pour utiliser des algorithmes de classification binaire dans le cadre de la classification multi-classes.\n",
        "\n",
        "Comme pour la méthode one-vs-rest, la méthode one-vs-one divise un ensemble de données de classification multi-classes en problèmes de classification binaire. Contrairement à la méthode one-vs-rest qui divise l'ensemble en un ensemble binaire pour chaque classe, l'approche one-vs-one divise l'ensemble en un ensemble pour chaque classe par rapport à chaque autre classe.\n",
        "\n",
        "Par exemple, considérons un problème de classification multi-classes avec quatre classes : 'rouge', 'bleu', 'vert' et 'jaune'. Cela pourrait être divisé en six ensembles de données de classification binaire comme suit :\n",
        "\n",
        "* Problème de Classification Binaire 1 : rouge vs bleu\n",
        "* Problème de Classification Binaire 2 : rouge vs vert\n",
        "* Problème de Classification Binaire 3 : rouge vs jaune\n",
        "* Problème de Classification Binaire 4 : bleu vs vert\n",
        "* Problème de Classification Binaire 5 : bleu vs jaune\n",
        "* Problème de Classification Binaire 6 : vert vs jaune\n",
        "\n",
        "\n",
        "Cela nécessite significativement plus d'ensembles de données et, par conséquent, de modèles que la stratégie one-vs-rest décrite dans la section précédente.\n",
        "\n",
        "La formule pour calculer le nombre d'ensembles de données binaires, et donc de modèles, est la suivante :\n",
        "\n",
        "* **(NumClasses * (NumClasses - 1)) / 2**\n",
        "\n",
        "On peut voir que pour quatre classes, cela nous donne la valeur attendue de six problèmes de classification binaire :\n",
        "\n",
        "* (NumClasses * (NumClasses - 1)) / 2\n",
        "* (4 * (4 - 1)) / 2\n",
        "* (4 * 3) / 2\n",
        "* 12 / 2\n",
        "* 6\n",
        "\n",
        "Chaque modèle de classification binaire peut prédire une étiquette de classe, et la classe prédite par la stratégie one-vs-one est celle qui obtient le plus de prédictions ou de votes.\n",
        "\n",
        "De même, si les modèles de classification binaire prédisent une adhésion à une classe numérique, telle qu'une probabilité, alors l'argmax de la somme des scores (classe avec le plus grand score total) est prédit comme l'étiquette de classe.\n",
        "\n",
        "Classiquement, cette approche est suggérée pour les machines à vecteurs de support (SVM) et les algorithmes liés basés sur le noyau. Cela est considéré car la performance des méthodes basées sur le noyau ne s'échelonne pas proportionnellement à la taille de l'ensemble d'entraînement, et l'utilisation de sous-ensembles des données d'entraînement peut contrecarrer cet effet.\n",
        "\n",
        "L'implémentation de la machine à vecteurs de support dans scikit-learn est fournie par la classe SVC et prend en charge la méthode one-vs-one pour les problèmes de classification multi-classes. Cela peut être réalisé en réglant l'argument \"decision_function_shape\" sur 'ovo'.\n",
        "\n",
        "**L'exemple ci-dessous** illustre la SVM pour la classification multi-classes en utilisant la méthode one-vs-one."
      ],
      "metadata": {
        "id": "uLb448Qad1oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM for multi-class classification using built-in one-vs-one\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "# define model\n",
        "model = SVC(decision_function_shape='ovo')\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make predictions\n",
        "yhat = model.predict(X)"
      ],
      "metadata": {
        "id": "3azy1A2Gembw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La bibliothèque scikit-learn propose également une classe distincte appelée **OneVsOneClassifier** qui permet d'utiliser la stratégie one-vs-one avec n'importe quel classificateur.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSIwtmcreutH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM for multi-class classification using one-vs-one\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "# define model\n",
        "model = SVC()\n",
        "# define ovo strategy\n",
        "ovo = OneVsOneClassifier(model)\n",
        "# fit model\n",
        "ovo.fit(X, y)\n",
        "# make predictions\n",
        "yhat = ovo.predict(X)"
      ],
      "metadata": {
        "id": "AFsWOebOexMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **modèle parametrique :**\n",
        "Les hypothèses peuvent grandement simplifier le processus d'apprentissage, mais elles peuvent également limiter ce qui peut être appris. Les algorithmes qui simplifient la fonction à une forme connue sont appelés algorithmes d'apprentissage automatique paramétriques.\n",
        "\n",
        "\n",
        "\n",
        "Les algorithmes impliquent deux étapes :\n",
        "\n",
        "Sélectionner une forme pour la fonction.\n",
        "Apprendre les coefficients de la fonction à partir des données d'entraînement.\n",
        "Une forme fonctionnelle facile à comprendre pour la fonction de mappage est une ligne, comme celle utilisée dans la régression linéaire :\n",
        "\n",
        "**b0 + b1*x1 + b2*x2 = 0**\n",
        "\n",
        "dont **b0, b1 and b2** sont les coefficients de la ligne qui contrôlent l'intercept et la pente, et  **x1 and x2** sont deux variables d'entrée.\n",
        "\n",
        "Supposer la forme fonctionnelle d'une ligne simplifie grandement le processus d'apprentissage. Maintenant, tout ce que nous avons à faire, c'est estimer les coefficients de l'équation de la ligne et nous avons un modèle prédictif pour le problème.\n",
        "\n",
        "Souvent, la forme fonctionnelle supposée est une combinaison linéaire des variables d'entrée, et en tant que tels, les algorithmes d'apprentissage automatique paramétriques sont souvent également appelés \"algorithmes d'apprentissage automatique linéaires\".\n",
        "\n",
        "Le problème est que la fonction sous-jacente inconnue réelle peut ne pas être une fonction linéaire comme une ligne. Elle pourrait être presque une ligne et nécessiter une légère transformation des données d'entrée pour fonctionner correctement. Ou elle pourrait être totalement différente d'une ligne, auquel cas l'hypothèse est incorrecte et l'approche produira de mauvais résultats.\n",
        "\n",
        "Quelques exemples supplémentaires d'algorithmes d'apprentissage automatique paramétriques incluent :\n",
        "\n",
        "Régression logistique\n",
        "Analyse discriminante linéaire\n",
        "Perceptron\n",
        "Naive Bayes\n",
        "Réseaux neuronaux simples\n",
        "Avantages des algorithmes d'apprentissage automatique paramétriques :\n",
        "\n",
        "* Simplicité : Ces méthodes sont plus faciles à comprendre et à interpréter les résultats.\n",
        "* Rapidité : Les modèles paramétriques sont très rapides à apprendre à partir des données.\n",
        "* Moins de données : Ils ne nécessitent pas autant de données d'entraînement et peuvent bien fonctionner même si l'ajustement aux données n'est pas parfait.\n",
        "\n",
        "Limitations des algorithmes d'apprentissage automatique paramétriques :\n",
        "\n",
        "* Contraints : En choisissant une forme fonctionnelle, ces méthodes sont fortement contraintes à la forme spécifiée.\n",
        "\n",
        "* Complexité limitée : Les méthodes conviennent mieux à des problèmes plus simples.\n",
        "* Mauvais ajustement : En pratique, les méthodes ont peu de chances de correspondre à la fonction de mappage sous-jacente.\n"
      ],
      "metadata": {
        "id": "Iip8qsZie6Ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#** Les modèles non paramétriques**\n",
        "\n",
        "Les algorithmes qui ne font pas d'hypothèses fortes sur la forme de la fonction de mappage sont appelés algorithmes d'apprentissage automatique non paramétriques. En ne faisant pas d'hypothèses, ils sont libres d'apprendre n'importe quelle forme fonctionnelle à partir des données d'entraînement.\n",
        "\n",
        "Les méthodes non paramétriques cherchent à mieux ajuster les données d'entraînement en construisant la fonction de mappage, tout en maintenant une certaine capacité à généraliser aux données invisibles. En tant que tels, ils peuvent s'adapter à un grand nombre de formes fonctionnelles.\n",
        "\n",
        "Un modèle non paramétrique facile à comprendre est l'algorithme des k plus proches voisins qui fait des prédictions basées sur les k motifs d'entraînement les plus similaires pour une nouvelle instance de données. La méthode ne suppose rien sur la forme de la fonction de mappage autre que des motifs proches sont susceptibles d'avoir une variable de sortie similaire.\n",
        "\n",
        "Quelques exemples supplémentaires d'algorithmes populaires d'apprentissage automatique non paramétriques sont :\n",
        "\n",
        "* k Plus Proches Voisins\n",
        "* Arbres de Décision comme CART et C4.5\n",
        "* Machines à Vecteurs de Support\n",
        "\n",
        "Avantages des algorithmes d'apprentissage automatique non paramétriques :\n",
        "\n",
        "* Flexibilité : Capables de s'adapter à un grand nombre de formes fonctionnelles.\n",
        "* Puissance : Aucune hypothèse (ou des hypothèses faibles) sur la fonction sous-jacente.\n",
        "* Performance : Peut donner des modèles de prédiction de performance supérieure.\n",
        "\n",
        "Limitations des algorithmes d'apprentissage automatique non paramétriques :\n",
        "\n",
        "* Plus de données : Nécessitent beaucoup plus de données d'entraînement pour estimer la fonction de mappage.\n",
        "* Plus lents : Beaucoup plus lents à s'entraîner car ils ont souvent beaucoup plus de paramètres à entraîner.\n",
        "* Surajustement : Plus de risques de surajuster les données d'entraînement, et il est plus difficile d'expliquer pourquoi des prédictions spécifiques sont faites."
      ],
      "metadata": {
        "id": "XyJcbqUhhUqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paramètre :**\n",
        "\n",
        "Un paramètre est une variable de configuration interne à un modèle et est appris à partir des données d'entraînement. Il fait partie intégrante du modèle et définit son comportement. Les paramètres sont les coefficients dans les modèles de régression, les poids dans les réseaux neuronaux, ou les points de division dans les arbres de décision. Au cours du processus d'entraînement, ces valeurs sont ajustées pour minimiser l'erreur dans les prédictions.\n",
        "\n",
        "**Hyperparamètre :**\n",
        "\n",
        "Un hyperparamètre, en revanche, est une configuration externe au modèle et dont la valeur ne peut pas être estimée à partir des données. Il est défini avant le processus d'entraînement et influence le processus d'apprentissage mais n'est pas appris à partir des données. Des exemples d'hyperparamètres incluent le taux d'apprentissage dans le boosting, le nombre de couches cachées dans un réseau neuronal ou la profondeur d'un arbre de décision."
      ],
      "metadata": {
        "id": "SLrLYTLte6bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projet**"
      ],
      "metadata": {
        "id": "QXyuC0Jei61y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **base de données des diabètes :**"
      ],
      "metadata": {
        "id": "bP8ciDjfjfom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aogPe2sie2nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ids4 /classification/diabetes.csv')"
      ],
      "metadata": {
        "id": "fjg2bX0BjNhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application svm one classe**\n"
      ],
      "metadata": {
        "id": "EfLVZaVTi39H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ik_4mT6kukz",
        "outputId": "b62b86db-7f4a-401a-c9a7-cb7e5fd0ae9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
        "\n",
        "\n",
        "# Assume the target variable is 'diabetes', where 1 indicates diabetes and 0 indicates non-diabetes\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Use only non-diabetic instances for training the One-Class SVM\n",
        "X_normal = X[y == 0]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, _, _ = train_test_split(X_normal, [0] * len(X_normal), test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X)\n",
        "\n",
        "# Create and train the One-Class SVM model\n",
        "model = OneClassSVM(nu=0.1, kernel='rbf')  # Adjust hyperparameters as needed\n",
        "model.fit(X_train_scaled)\n",
        "\n",
        "# Make predictions on the entire dataset\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6hvO9jWrVkE",
        "outputId": "b1c24118-a9c9-49a4-e180-3864012fc7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81640625\n",
            "Recall: 0.81640625\n",
            "precision: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation des performances :**\n"
      ],
      "metadata": {
        "id": "xn0fCGwjoJir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score([1] * len(X), y_pred)  # Assuming 1 represents normal class in the output\n",
        "recall = recall_score([1] * len(X), y_pred)\n",
        "precision = precision_score([1] * len(X), y_pred)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY_khzG7sBOu",
        "outputId": "37ed039c-443b-4385-f50b-cf6b9edea3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81640625\n",
            "Recall: 0.81640625\n",
            "precision: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application SMV multi-class**"
      ],
      "metadata": {
        "id": "Uil2XYSJnm1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report\n",
        "\n",
        "\n",
        "# Assume the target variable is 'diabetes', which is a categorical variable with multiple classes\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the SVM model\n",
        "model = SVC(kernel='linear', C=1.0)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "56vy1I6FnuVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation des performances**"
      ],
      "metadata": {
        "id": "9NbF8zjSso5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14CsQyKIslRb",
        "outputId": "9314d753-8340-4638-d705-01cf7215a8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7597402597402597\n",
            "Recall: 0.7597402597402597\n",
            "Precision: 0.7588095238095239\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81        99\n",
            "           1       0.67      0.65      0.66        55\n",
            "\n",
            "    accuracy                           0.76       154\n",
            "   macro avg       0.74      0.74      0.74       154\n",
            "weighted avg       0.76      0.76      0.76       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **base de données iris :**"
      ],
      "metadata": {
        "id": "zMh5ZJKEtUXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application svm one classe**"
      ],
      "metadata": {
        "id": "4gnrpAO-tjIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the SVM model\n",
        "model = SVC(kernel='linear', C=1.0)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "auc = roc_auc_score(pd.get_dummies(y_test), model.decision_function(X_test_scaled), multi_class='ovr')  # 'ovr' for multi-class AUC\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"AUC:\", auc)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zt0DDuNsvbu",
        "outputId": "6c559d56-9683-48c6-a01f-c3bf2ff6b566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "Recall: 0.9666666666666667\n",
            "Precision: 0.9694444444444444\n",
            "AUC: 0.980599647266314\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application svm multi-classe**"
      ],
      "metadata": {
        "id": "7XUVHaFvtwBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the SVM model\n",
        "model = SVC(kernel='linear', C=1.0)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # For multi-class\n",
        "auc = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred), multi_class='ovr')  # 'ovr' for multi-class AUC\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"AUC:\", auc)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjeyCvL9tK_L",
        "outputId": "1d625acc-7542-44d4-fcae-6654818efd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "Recall: 0.9666666666666667\n",
            "Precision: 0.9694444444444444\n",
            "AUC: 0.9727095516569201\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piYx2IPFtxsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}